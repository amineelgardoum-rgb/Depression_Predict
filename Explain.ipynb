{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a84d174",
   "metadata": {},
   "source": [
    "# Importing Required Libraries\n",
    "This section explains the purpose of importing libraries like pandas, numpy, matplotlib, seaborn, and sklearn. These libraries are essential for data manipulation, visualization, and machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef2c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a15208a",
   "metadata": {},
   "source": [
    "# Loading the Dataset\n",
    "The dataset is loaded using pandas, and its structure is briefly explored to understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e72cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Dataset\n",
    "df = pd.read_csv(\"DepressionData.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab637845",
   "metadata": {},
   "source": [
    "# Exploring the Dataset\n",
    "We use methods like `df.info()`, `df.head()`, and `df.describe()` to explore the dataset and gain insights into its structure and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17446561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the Dataset\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ece5f92",
   "metadata": {},
   "source": [
    "# Handling Missing Values\n",
    "Missing values are handled using methods like `dropna()` and `isnull().sum()`. This ensures the dataset is clean and ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152f7295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Missing Values\n",
    "df.dropna(inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61879f2",
   "metadata": {},
   "source": [
    "# Encoding Categorical Variables\n",
    "Categorical variables are mapped to numerical values using dictionaries and the `map()` function. This step is crucial for machine learning models that require numerical input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13766dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Categorical Variables\n",
    "mapping_value = {value: idx + 1 for idx, value in enumerate(df[\"City\"].unique())}\n",
    "df[\"City\"] = df[\"City\"].map(mapping_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b85192",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "New features like `total Stress` are created, and existing features like `Sleep Duration` are transformed to enhance the dataset's predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15a777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "df[\"total Stress\"] = df[\"Academic Pressure\"] + df[\"Work Pressure\"] + df[\"Financial Stress\"]\n",
    "\n",
    "def extract_numbers(input_string, as_int=True):\n",
    "    import re\n",
    "    if as_int:\n",
    "        numbers = list(map(int, re.findall(r'\\d+', input_string)))\n",
    "    else:\n",
    "        numbers = list(map(float, re.findall(r'\\d+\\.?\\d*', input_string)))\n",
    "    return numbers\n",
    "\n",
    "df[\"Sleep Duration\"] = df[\"Sleep Duration\"].apply(extract_numbers)\n",
    "\n",
    "def calculate_midpoint(numbers):\n",
    "    if len(numbers) == 1:\n",
    "        return numbers[0]\n",
    "    elif len(numbers) == 2:\n",
    "        return (numbers[0] + numbers[1]) / 2\n",
    "\n",
    "df[\"Sleep Duration\"] = df[\"Sleep Duration\"].apply(calculate_midpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901318cd",
   "metadata": {},
   "source": [
    "# Correlation Analysis\n",
    "Correlation between features is analyzed using `df.corr()` and visualized using a heatmap with seaborn. This helps identify relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbf2638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(df.corr(), annot=True, fmt='.1f', cmap='viridis')\n",
    "plt.title(\"Heatmap of the Correlation\")\n",
    "plt.savefig(\"HeatMap.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e8d2ab",
   "metadata": {},
   "source": [
    "# Building the Machine Learning Model\n",
    "The dataset is split into training and testing sets. A RandomForestClassifier is trained, and predictions are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecee0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Machine Learning Model\n",
    "X = df[['total Stress', 'Sleep Duration', 'Dietary Habits', \n",
    "        'Family History of Mental Illness', 'Job Satisfaction', \n",
    "        'Age', 'Profession', 'Have you ever had suicidal thoughts ?']]\n",
    "Y = df['Depression']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75801978",
   "metadata": {},
   "source": [
    "# Evaluating the Model\n",
    "The model is evaluated using metrics like `accuracy_score`, `classification_report`, and a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e39f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the Model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Depression', 'Depression'], yticklabels=['No Depression', 'Depression'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cf14e5",
   "metadata": {},
   "source": [
    "# Saving and Reloading the Processed Data\n",
    "The processed data is saved to a CSV file and reloaded for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8698325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and Reloading the Processed Data\n",
    "df.to_csv(\"NewData.csv\", index=False)\n",
    "df = pd.read_csv(\"NewData.csv\")\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
